%you might want to include at some point the idea that databases in general are used to teach computers about the world, and to get them to to do things that humans can do, but not computers.

In \gls{mir}, the database is \textit{in front} of the programmer, \textit{next} to the computer. This practice combines \gls{ir} with Music Theory, and it has been present in academia for a while, most generally within Electrical Engineering departments. The objective of \gls{mir} is to obtain useful information from the analysis of sound signals. That is, \gls{mir} seeks to represent a complex signal with a small number of data points, thus defining a a navigable `information space,' which is, quite literally, the discretized space of the database.

\img{mir}{png}{0.3}{
	Diagram of database performance in \gls{mir} practices. The database is visibly next to the computer, and the two bottom arrows indicate the intervention of the human operator.
}

For instance, out of sound file containing millions of samples, information space reduces these points to a database of few `descriptors' that point to certain `features' of the sound file. A descriptor is, in essence, a small amount of data that identifies other larger data. In this case, a feature descriptor relates to the values of a certain characteristics of the analyzed audio file, such as spectral centroid, brightness, flatness, etc. 

Over the 18 years of the \gls{ismir} conference, more than thirty databases of this sort have been publicly created and released, as a means to classify millions of songs and musical genres. This type of database navigation has been used to perform automatic tasks such as categorization for recommendation systems \parencites{Tza02:Mus}{DBLP:journals/corr/abs-0812-4235}{asmita_poddar_2018_1422565}, track separation or instrument recognition, and score transcriptions, among other uses (see below). A recent emphasis in open source database creation has gained momentum \parencite{DBLP:conf/ismir/FonsecaPFFBFOPS17}, such as the \gls{freesound} or \gls{looperman} databases, or \gls{cmam}'s \gls{telemeta}, both collaborative database systems: the first two for general sound file sharing and classification, the latter for ethno-musicological pursposes. Audio databases such as \gls{freesound} or \gls{looperman} have been growing exponentially, as well as their use within live performances and interactive systems \parencite{nuno_n_correia_2010_849729}. Automatic audio description and clustering among these databases automatic have improved greatly their usability \parencite{gerard_roma_2012_850102}. \textcite{collins_2015} created open-source software implementing \gls{mir} techniques for navigation, analysis, and classification of the electronic music archive within \gls{ubuweb}. 

Before sound and audio descriptor databases, however, music notation databases have been developed with a variety of file formats \see{applications:notation}. Some examples of these notation databases can be the Polish folksong database in the \gls{esac} format, the electronic library for musical scores \gls{musedata}, the \gls{rism} database, the \textit{Kern Scores} database,\footnote{\url{http://kern.ccarh.org/}} among others. In turn, these databases have been a fruitful area of exploration in Computational Musicology \parencite{DBLP:conf/iciso/Yokl11}, for which toolkits such as \gls{mit}'s \gls{music21} have been developed. Two examples of widely used libraries for audio analysis, classification, and synthesis are \gls{marsyas} \parencite{tzanetakis_cook_2000} and the \gls{essentia} \parencite{DBLP:conf/ismir/BogdanovWGGHMRSZS13}. For a more general overview of \gls{mir} software, see \parencite{DBLP:conf/ismir/BogdanovWGGHMRSZS13}. The different applications of databases are endless and so varied that would extend the scope of this study.\footnote{For example, consider the \gls{mimo} database, a project dedicated to the cataloguing of musical instruments, and how it was used for the statistical tracking of the evolution of the violin based on pattern recognition of its shapes \parencite{2018arXiv180802848P}} Some specific uses that \gls{mir} has given to databases have been:

\begin{itemize}


\item for audio classification and clustering \parencites{ilprints489}{DBLP:conf/ismir/HomburgMMMW05}{marcelo_queiroz_2018_1422585}
\item for genre recognition and classification \parencites{Tza02:Mus}{DBLP:conf/icmc/XuZY05}{DBLP:conf/ismir/SillaKK08}{icmc/bbp2372.2010.003}{DBLP:journals/corr/abs-1803-04652}{DBLP:journals/corr/WangH17a}{DBLP:journals/corr/MitraS14}{2010NJPh:12e3030C}{DBLP:journals/corr/abs-0812-4235}

\item to describe performance expression \parencite{DBLP:conf/ismir/HashidaMK08}{mitsuyo_hashida_2017_1401963}{mitsuyo_hashida_2018_1422503}
\item for emotion recognition and color associations in the listener \parencite{DBLP:conf/ismir/PesekGPSGSPM14}
\item for multimodal mood prediction \parencites{DBLP:journals/corr/abs-1809-07276}{xiao_hu_2014_850795}{humberto_corona_2015_851021}


\item for multi-instrument recognition \parencite{DBLP:conf/ismir/HumphreyDM18}
\item for the evaluation of multiple-source}{fundamental frequency estimation algorithms \parencite{DBLP:conf/ismir/YehBR07}
\item for contextual music listening pattern detection using social media \parencite{DBLP:conf/ismir/HaugerSKT13}
\item for melody \parencite{ioannis_karydis_2007_849469}{DBLP:conf/ismir/BittnerSTMCB14} or singing voice \parencite{DBLP:journals/corr/abs-1711-00048} extraction


\item for structural analysis \parencite{DBLP:conf/ismir/SmithBFRD11}
\item for schenkerian analysis \parencite{DBLP:conf/ismir/Kirlin14}
\item for harmonic analysis \parencite{DBLP:conf/ismir/DevaneyACN15}
\item for melodic similarity \parencite{goffredo_haus_2005_849297}
\item for forensic analysis as a complement of video analysis \parencite{serizel:hal-01393959}
\item for the evaluation of tempo estimation and key detection algorithms \parencite{DBLP:conf/ismir/KneesFHVBHG15}
\item for tonal music analysis using \gls{gttm} \parencite{DBLP:conf/ismir/HamanakaHT14}
\item for counterpoint analysis \parencite{DBLP:conf/ismir/AntilaC14}


\item to train models for phoneme detection \parencite{DBLP:conf/ismir/ProutskovaRWC12} and music source separation \parencite{marius_miron_2017_1401923}
\item for training and evaluating chord transcription algorithms \parencite{DBLP:conf/ismir/EremenkoDBS18}
\item for training querying methods \parencites{mark_cartwright_2012_850060}{DBLP:journals/corr/Brzezinski-SpiczakDLP13}{DBLP:journals/corr/NagaviB14}{DBLP:journals/corr/abs-1301-1894}{icmc/bbp2372.1999.355} 

% proposed a \gls{mir} system aimed at query-by-content navigation of a musical collection based on melodic segmentation. In their research, they implemented a \gls{lbdm} to perform the automatic segmentation of melodic information taken from \gls{midi} files of Baroque, Classical and Romantic music. They then proceeded to normalize and index the melodic phrases into separate files for querying.

\item for adversarial audio synthesis \parencite{2018arXiv180204208D}
\item for orchestration \parencite{DBLP:conf/ismir/CrestelEHM17}
\item for modeling carnatic rhythm generation \parencite{carlos_guedes_2018_1422615}

\item to create digital libraries \parencite{DBLP:conf/ismir/Dunn00}
\item to store music notation \parencite{DBLP:conf/ismir/Good00}
\end{itemize}

For further reference, the following citations point to different audio databases which have been created over the years: \textcites{DBLP:conf/ismir/GotoHNO02}{DBLP:conf/ismir/GotoHNO03}{DBLP:conf/ismir/WustC04}{DBLP:conf/ismir/MaxwellE08}{DBLP:conf/ismir/Bertin-MahieuxEWL11}{DBLP:conf/ismir/Karaosmanoglu12}{Jaimovich:2012}{Mital:2013}{bbortz:2015}{jjaimovich:2015,Nort2016}{ DBLP:conf/ismir/DefferrardBVB17}{DBLP:conf/ismir/VigliensoniF17}{DBLP:conf/ismir/Meseguer-Brocal18}{DBLP:conf/ismir/DonahueMM18}{DBLP:conf/ismir/XiBPYB18}{DBLP:conf/ismir/WilkinsSWP18}.