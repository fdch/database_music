A detailed description of the image and audio navigation system\dots


\begin{quote}
	Just as a fractal has the same structure on different scales, a new media object has the same modular structure throughout. Media elements\dots are represented as collections of discrete samples \parencite[30]{Man01:The}.
\end{quote}

\begin{quote}
	First, data is sampled, most often at regular intervals, such as the grid of pixels used to represent a digital image. The frequency of sampling is referred to as resolution. Sampling turns continuous data into discrete data\dots Second, each sample is quantified, that is, it is assigned a numerical value drawn from a defined range (such as 0-255 in the case of an 8-bit greyscale image) \parencite[28]{Man02:Old}
\end{quote}

I define the points in common between Database Practice and Music Composition. I describe the main technical concepts behind Database Navigation and provide use cases from both appendices A and B, the former relating to joint image and audio databases, and the latter to text databases. I then reflect on the quality of this navigation in relation to the type of navigation and results that they obtain.

I use computer vision literature to briefly introduce and describe the most common visual descriptors. I focus on certain descriptors (TBD) which are suitable for live multimedia use, and which I will implement in Appendix A.

I use Timbre Analysis literature to briefly introduce and describe the most useful audio descriptors. I take William Brent's TimbreID library, complementing it with Tae Hong Park's dissertation on timbre recognition, and I focus on the most useful descriptors for live multimedia use (TBD), which I will implement in Appendix A in relation to the image descriptors introduced above.